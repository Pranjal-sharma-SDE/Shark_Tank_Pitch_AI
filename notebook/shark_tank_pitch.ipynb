{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f3f6938",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import scipy.signal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33daf332",
   "metadata": {},
   "source": [
    "## Pipeline 1 : Voice & Tone Analysis\n",
    "\n",
    "input : audio file\n",
    "\n",
    "output : * Vocal Features (like - pitch, pace,pause)\n",
    "         * Tone \n",
    "         * Negative Behavioral Traits\n",
    "         * Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8be155e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- üé§ Analyzing: ../data/sample_pitch.wav ---\n",
      "\n",
      "--- üìä ANALYSIS RESULTS ---\n",
      "Detected Emotion: CONFIDENT / BALANCED\n",
      "Delivery Score:   52/100\n",
      "Hesitation Index: 0.28 (Lower is better)\n",
      "Pitch Variation:  12.77 Hz\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "class VoiceAnalyzer:\n",
    "    def __init__(self, audio_path):\n",
    "        self.audio_path = audio_path\n",
    "        try:\n",
    "            self.y, self.sr = librosa.load(audio_path, sr=None)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading audio: {e}\")\n",
    "            self.y, self.sr = None, None\n",
    "\n",
    "    def analyze_pitch(self):\n",
    "        \"\"\"\n",
    "        Analyzes Fundamental Frequency (F0).\n",
    "        \"\"\"\n",
    "        f0, voiced_flag, voiced_probs = librosa.pyin(\n",
    "            self.y, fmin=librosa.note_to_hz('C2'), fmax=librosa.note_to_hz('C7')\n",
    "        )\n",
    "        valid_pitch = f0[~np.isnan(f0)]\n",
    "        \n",
    "        if len(valid_pitch) == 0:\n",
    "            return {\"avg_pitch_hz\": 0, \"pitch_variation\": 0, \"f0_series\": []}\n",
    "\n",
    "        return {\n",
    "            \"avg_pitch_hz\": round(np.mean(valid_pitch), 2),\n",
    "            \"pitch_variation\": round(np.std(valid_pitch), 2),\n",
    "            \"f0_series\": valid_pitch  # Keep for filler detection\n",
    "        }\n",
    "\n",
    "    def analyze_volume(self):\n",
    "        \"\"\"\n",
    "        Analyzes Energy/Volume.\n",
    "        \"\"\"\n",
    "        rms = librosa.feature.rms(y=self.y)[0]\n",
    "        return {\n",
    "            \"avg_volume\": round(float(np.mean(rms)), 4),\n",
    "            \"volume_dynamic_range\": round(float(np.max(rms) - np.min(rms)), 4),\n",
    "            \"rms_series\": rms\n",
    "        }\n",
    "\n",
    "    def analyze_fluency(self, f0_series, rms_series):\n",
    "        \"\"\"\n",
    "        Detects negative behaviors: Hesitations and Monotone \"Fillers\".\n",
    "        \"\"\"\n",
    "        # 1. Hesitation Index (Silence Ratio)\n",
    "        non_silent = librosa.effects.split(self.y, top_db=20)\n",
    "        non_silent_dur = sum((end - start) / self.sr for start, end in non_silent)\n",
    "        total_dur = librosa.get_duration(y=self.y, sr=self.sr)\n",
    "        \n",
    "        hesitation_index = (total_dur - non_silent_dur) / total_dur if total_dur > 0 else 0\n",
    "\n",
    "        # 2. Potential Filler Words (Heuristic: Long, Flat Pitch, Low Energy)\n",
    "        # \"Umm\" is usually >300ms of voiced sound with very low pitch variance.\n",
    "        # We look for continuous voiced segments with std_dev(pitch) < threshold.\n",
    "        \n",
    "        # Note: This is a signal proxy. True filler detection needs ASR.\n",
    "        # Here we count segments of stable pitch as \"monotone holds\".\n",
    "        \n",
    "        # Calculate pitch derivative (change over time)\n",
    "        if len(f0_series) > 0:\n",
    "            pitch_derivative = np.abs(np.diff(f0_series))\n",
    "            # Count frames where pitch changes very little (flat tone)\n",
    "            flat_pitch_frames = np.sum(pitch_derivative < 2.0) \n",
    "            monotone_ratio = flat_pitch_frames / len(f0_series)\n",
    "        else:\n",
    "            monotone_ratio = 0\n",
    "\n",
    "        return {\n",
    "            \"hesitation_index\": round(hesitation_index, 2), # 0.0 - 1.0 (High is bad)\n",
    "            \"monotone_ratio\": round(monotone_ratio, 2)      # 0.0 - 1.0 (High is robotic)\n",
    "        }\n",
    "\n",
    "    def detect_emotional_tone(self, pitch_data, vol_data, fluency_data):\n",
    "        \"\"\"\n",
    "        Infers emotion based on acoustic combinations.\n",
    "        \"\"\"\n",
    "        pitch_var = pitch_data.get(\"pitch_variation\", 0)\n",
    "        vol_range = vol_data.get(\"volume_dynamic_range\", 0)\n",
    "        pace = fluency_data.get(\"hesitation_index\", 0) # High hesitation = Nervous\n",
    "\n",
    "        # Heuristic Decision Tree\n",
    "        if pitch_var > 40 and vol_range > 0.05:\n",
    "            return \"Enthusiastic / Excited\"\n",
    "        elif pitch_var < 10 and vol_range < 0.02:\n",
    "            return \"Bored / Monotone\"\n",
    "        elif pace > 0.30: # >30% silence\n",
    "            return \"Nervous / Hesitant\"\n",
    "        else:\n",
    "            return \"Confident / Balanced\"\n",
    "\n",
    "    def calculate_delivery_score(self, pitch_data, vol_data, fluency_data):\n",
    "        \"\"\"\n",
    "        Generates a 0-100 score based on weighted best practices.\n",
    "        \"\"\"\n",
    "        score = 100\n",
    "        \n",
    "        # 1. Penalize Monotony (Low Pitch Variation)\n",
    "        pv = pitch_data['pitch_variation']\n",
    "        if pv < 15: score -= 20  # Too robotic\n",
    "        elif pv > 80: score -= 10 # Too erratic\n",
    "        \n",
    "        # 2. Penalize Hesitation\n",
    "        hes = fluency_data['hesitation_index']\n",
    "        if hes > 0.20: score -= (hes * 100) # Heavy penalty for silence\n",
    "        \n",
    "        # 3. Reward Energy (Volume Range)\n",
    "        vol = vol_data['volume_dynamic_range']\n",
    "        if vol < 0.02: score -= 15 # Too quiet/flat\n",
    "        \n",
    "        return max(0, int(score))\n",
    "\n",
    "    def run_full_analysis(self):\n",
    "        if self.y is None: return \"Error\"\n",
    "        \n",
    "        print(f\"--- üé§ Analyzing: {self.audio_path} ---\")\n",
    "        \n",
    "        # Run sub-modules\n",
    "        pitch = self.analyze_pitch()\n",
    "        volume = self.analyze_volume()\n",
    "        fluency = self.analyze_fluency(pitch['f0_series'], volume['rms_series'])\n",
    "        \n",
    "        # High-level insights\n",
    "        emotion = self.detect_emotional_tone(pitch, volume, fluency)\n",
    "        score = self.calculate_delivery_score(pitch, volume, fluency)\n",
    "        \n",
    "        \n",
    "        \n",
    "        results = {\n",
    "            \"metrics\": {**pitch, **volume, **fluency},\n",
    "            \"emotion\": emotion,\n",
    "            \"delivery_score\": score\n",
    "        }\n",
    "\n",
    "        # Pretty Print\n",
    "        print(\"\\n--- üìä ANALYSIS RESULTS ---\")\n",
    "        print(f\"Detected Emotion: {emotion.upper()}\")\n",
    "        print(f\"Delivery Score:   {score}/100\")\n",
    "        print(f\"Hesitation Index: {fluency['hesitation_index']} (Lower is better)\")\n",
    "        print(f\"Pitch Variation:  {pitch['pitch_variation']} Hz\")\n",
    "        \n",
    "        return results\n",
    "\n",
    "# Example Usage\n",
    "# analyzer = VoiceAnalyzer(\"my_pitch.wav\")\n",
    "# data = analyzer.run_full_analysis()\n",
    "\n",
    "analyzer = VoiceAnalyzer(\"../data/sample_pitch.wav\")\n",
    "data = analyzer.run_full_analysis()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5646b5ae",
   "metadata": {},
   "source": [
    "## Pipeline 2 : Content & Business Logic Analysis\n",
    "\n",
    "input : audio file\n",
    "\n",
    "output : * Business Logic\n",
    "         * Transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4531c4dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1. Transcribing Audio ---\n",
      "Transcript Preview: Thousands of women are struggling to access critical ob-gyn services due to clinic closures and long...\n",
      "--- 2. Analyzing Business Logic ---\n",
      "{\n",
      "  \"transcript\": \"Thousands of women are struggling to access critical ob-gyn services due to clinic closures and long wait times. Recent closures have left a gap in women's health care, forcing patients to wait months for critical services like ob-gyn checkups, prenatal care and wellness exams. For women in rural areas, the problem is even worse. Many are simply unable to access the care they need. There is an urgent demand for a health care solution that can bridge this gap, particularly as the population continues to grow. Our advanced practice registered nurse led women's health clinic solves this problem by providing high quality affordable care with a fixed payment model, eliminating the need for insurances and surprise bills.\",\n",
      "  \"analysis\": {\n",
      "    \"pitch_structure\": {\n",
      "      \"hook_segment\": \"Thousands of women are struggling to access critical ob-gyn services due to clinic closures and long wait times.\",\n",
      "      \"problem_segment\": \"Recent closures have left a gap in women's health care, forcing patients to wait months for critical services like ob-gyn checkups, prenatal care and wellness exams.\",\n",
      "      \"solution_segment\": \"Our advanced practice registered nurse led women's health clinic solves this problem by providing high quality affordable care with a fixed payment model, eliminating the need for insurances and surprise bills.\",\n",
      "      \"ask_segment\": null\n",
      "    },\n",
      "    \"scores\": {\n",
      "      \"problem\": 9,\n",
      "      \"solution\": 8,\n",
      "      \"market\": 7,\n",
      "      \"model\": 7,\n",
      "      \"ask\": 0\n",
      "    },\n",
      "    \"viability_score\": 62,\n",
      "    \"missing_elements\": [\n",
      "      \"Detailed market size analysis\",\n",
      "      \"Specific investment request\",\n",
      "      \"Revenue projections\"\n",
      "    ],\n",
      "    \"red_flags\": [\n",
      "      \"Lack of financial details or investment request\"\n",
      "    ],\n",
      "    \"summary_critique\": \"The pitch effectively identifies a clear and urgent problem in women's healthcare access. However, it lacks a specific investment request and financial details crucial for evaluating viability.\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Initialize client\n",
    "client = OpenAI(api_key=key)\n",
    "\n",
    "class ContentAnalyzer:\n",
    "    def __init__(self, audio_path):\n",
    "        self.audio_path = audio_path\n",
    "        self.transcript = \"\"\n",
    "\n",
    "    def transcribe_audio(self):\n",
    "        \"\"\"\n",
    "        Step 1: Convert Speech to Text using OpenAI Whisper.\n",
    "        \"\"\"\n",
    "        print(\"--- 1. Transcribing Audio ---\")\n",
    "        try:\n",
    "            with open(self.audio_path, \"rb\") as audio_file:\n",
    "                transcription = client.audio.transcriptions.create(\n",
    "                    model=\"whisper-1\", \n",
    "                    file=audio_file\n",
    "                )\n",
    "            self.transcript = transcription.text\n",
    "            print(f\"Transcript Preview: {self.transcript[:100]}...\")\n",
    "            return self.transcript\n",
    "        except Exception as e:\n",
    "            print(f\"Transcription Error: {e}\")\n",
    "            self.transcript = \"\"\n",
    "            return None\n",
    "\n",
    "    def analyze_business_logic(self):\n",
    "        \"\"\"\n",
    "        Step 2: Evaluate the Pitch Structure & Business Viability using GPT-4o.\n",
    "        \"\"\"\n",
    "        if not self.transcript:\n",
    "            return {\"error\": \"No transcript available to analyze.\"}\n",
    "\n",
    "        print(\"--- 2. Analyzing Business Logic ---\")\n",
    "        \n",
    "        # Updated System Prompt to include Structure Detection & Viability Score\n",
    "        system_prompt = \"\"\"\n",
    "        You are a Venture Capital Analyst screening pitches for Shark Tank. \n",
    "        Analyze the provided pitch transcript for BUSINESS LOGIC and STRUCTURE.\n",
    "        \n",
    "        TASK 1: Structural Analysis\n",
    "        Identify the specific sentences or phrases that correspond to these sections:\n",
    "        - \"Hook\": The opening statement to grab attention.\n",
    "        - \"Problem\": The pain point being solved.\n",
    "        - \"Solution\": The product/service description.\n",
    "        - \"Ask\": The specific investment request (amount/equity).\n",
    "        (If a section is missing, return null).\n",
    "\n",
    "        TASK 2: Scoring (1-10 Scale)\n",
    "        Evaluate these 5 Key Pillars:\n",
    "        1. Problem Clarity: Is the pain point clear and urgent?\n",
    "        2. Solution Viability: Does the product actually solve the problem?\n",
    "        3. Market Size: Is the addressable market defined?\n",
    "        4. Business Model: Is it clear how they make money?\n",
    "        5. The \"Ask\": Is the valuation realistic?\n",
    "\n",
    "        TASK 3: Overall Viability Score (0-100)\n",
    "        Calculate a weighted score based on the 5 pillars above (Ask & Model are weighted highest).\n",
    "        \n",
    "        Output must be a valid JSON object with this exact structure:\n",
    "        {\n",
    "            \"pitch_structure\": {\n",
    "                \"hook_segment\": \"text or null\",\n",
    "                \"problem_segment\": \"text or null\",\n",
    "                \"solution_segment\": \"text or null\",\n",
    "                \"ask_segment\": \"text or null\"\n",
    "            },\n",
    "            \"scores\": {\"problem\": 0, \"solution\": 0, \"market\": 0, \"model\": 0, \"ask\": 0},\n",
    "            \"viability_score\": 0,\n",
    "            \"missing_elements\": [\"List of critical missing info\"],\n",
    "            \"red_flags\": [\"List of logical fallacies\"],\n",
    "            \"summary_critique\": \"A 2-sentence summary.\"\n",
    "        }\n",
    "        \"\"\"\n",
    "\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": f\"Pitch Transcript: \\\"{self.transcript}\\\"\"}\n",
    "            ],\n",
    "            response_format={\"type\": \"json_object\"} \n",
    "        )\n",
    "\n",
    "        try:\n",
    "            analysis_json = json.loads(response.choices[0].message.content)\n",
    "            return analysis_json\n",
    "        except json.JSONDecodeError:\n",
    "            return {\"error\": \"Failed to parse analysis results.\"}\n",
    "\n",
    "    def run_full_analysis(self):\n",
    "        # 1. Transcribe\n",
    "        self.transcribe_audio()\n",
    "        \n",
    "        # 2. Analyze\n",
    "        analysis_results = self.analyze_business_logic()\n",
    "        \n",
    "        # 3. Merge Transcript into Final Result\n",
    "        # This ensures the frontend has access to the raw text alongside the scores\n",
    "        final_output = {\n",
    "            \"transcript\": self.transcript,\n",
    "            \"analysis\": analysis_results\n",
    "        }\n",
    "        \n",
    "        return final_output\n",
    "\n",
    "# Example Usage:\n",
    "logic_analyzer = ContentAnalyzer(\"../data/sample_pitch.wav\")\n",
    "business_insights = logic_analyzer.run_full_analysis()\n",
    "print(json.dumps(business_insights, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac98addb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pitch_structure': {'hook_segment': 'Thousands of women are struggling to access critical ob-gyn services due to clinic closures and long wait times.',\n",
       "  'problem_segment': \"Recent closures have left a gap in women's health care, forcing patients to wait months for critical services like ob-gyn checkups, prenatal care and wellness exams.\",\n",
       "  'solution_segment': \"Our advanced practice registered nurse led women's health clinic solves this problem by providing high quality affordable care with a fixed payment model, eliminating the need for insurances and surprise bills.\",\n",
       "  'ask_segment': None},\n",
       " 'scores': {'problem': 9, 'solution': 8, 'market': 7, 'model': 7, 'ask': 0},\n",
       " 'viability_score': 62,\n",
       " 'missing_elements': ['Detailed market size analysis',\n",
       "  'Specific investment request',\n",
       "  'Revenue projections'],\n",
       " 'red_flags': ['Lack of financial details or investment request'],\n",
       " 'summary_critique': \"The pitch effectively identifies a clear and urgent problem in women's healthcare access. However, it lacks a specific investment request and financial details crucial for evaluating viability.\"}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "business_insights['analysis']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9c10ef",
   "metadata": {},
   "source": [
    "## Pipeline 3 : Content & Business Logic Analysis\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9fb1e2b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "ü¶à FINAL SHARK TANK VERDICT ü¶à\n",
      "==================================================\n",
      "--- üß† Synthesizing Feedback: The Royalty ---\n",
      "\n",
      "==================== THE ROYALTY ====================\n",
      "üó£Ô∏è \"Oh dear, you're trying to convince me with a violin solo about the struggles of women accessing ob-gyn services, yet somehow you can't manage to deliver this with any semblance of passion or urgency. Your Vocal Delivery Score of 52 is like a sedative; you are boring me to death. You need to wake up and make sure your pitch doesn't sound like it's directed at the walking dead.\n",
      "\n",
      "Now, let's dissect your business metrics. An Overall Viability Score of 62 is teetering on the edge of acceptability, I'll grant you that. Problem Clarity and Solution Viability are commendably high, but what on earth were you thinking with your Valuation? A big fat zero for The Ask? Are you trying to become the hero of a rags-to-riches story without ever actually asking for the riches? This is the kind of madness that will have you scratching for pennies like a cockroach under the fridge.\n",
      "\n",
      "And here we have red flags waving like it's a parade of bad decisions. No financial details, no investment request, no clarity on what you're looking for? This isn't the amateur hour, my friend. You must ask for what you need, not hope for a miracle.\n",
      "\n",
      "Listen, while your idea has some merit, your execution is abysmal. Get your financials in order, deliver your pitch with actual emotion, and for goodness' sake, have the courage to state your ask. I'm here to make money, not sit through a monotone lecture on healthcare disparities.\"\n",
      "\n",
      "üëâ VERDICT: Need More Info\n",
      "------------------------------------------------------------\n",
      "   üéôÔ∏è Generating audio for The Royalty (Voice: onyx)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_10736\\370241093.py:168: DeprecationWarning: Due to a bug, this method doesn't actually stream the response content, `.with_streaming_response.method()` should be used instead\n",
      "  response.stream_to_file(output_filename)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ‚úÖ Saved: Feedback/feedback_kevin.wav\n",
      "--- üß† Synthesizing Feedback: The Tech Visionary ---\n",
      "\n",
      "==================== THE TECH VISIONARY ====================\n",
      "üó£Ô∏è \"Alright, let's dive in. Your pitch highlighted a significant issue‚Äîwomen's access to crucial ob-gyn services. You nailed the Problem Clarity with a score of 9 out of 10, and your Solution Viability is strong at 8 out of 10. This reflects a deep understanding of the problem you're trying to solve, which is crucial for any startup seeking investment.\n",
      "\n",
      "However, there are some glaring issues we need to address. First off, your Vocal Delivery Score of 52 out of 100 is concerning. Despite the emotional tone detection as 'Confident / Balanced', the frequent awkward silences and monotone delivery suggest otherwise. High hesitation shows a lack of preparation or perhaps nerves. We can't afford hesitation when pitching a business that aims to transform such a critical area.\n",
      "\n",
      "But the most crucial red flag here is the absence of financial details or investment requests. This essentially translates to a zero in your valuation ask. You can't walk into the tank without a clearly defined ask; it's like showing up to a game without a strategy. I need to know what you're seeking from us, not just in terms of money, but how you plan to use it to address this enormous gap in women's healthcare.\n",
      "\n",
      "Solution Viability and Problem Clarity are strong points for you, but without a concrete financial plan or an investment request, it's hard to evaluate the business potential. You need to regroup, define your financial strategy, and come back with a clear, compelling ask.\"\n",
      "\n",
      "üëâ VERDICT: Need More Info\n",
      "------------------------------------------------------------\n",
      "   üéôÔ∏è Generating audio for The Tech Visionary (Voice: echo)...\n",
      "      ‚úÖ Saved: Feedback/feedback_mark.wav\n",
      "--- üß† Synthesizing Feedback: The Brand Guru ---\n",
      "\n",
      "==================== THE BRAND GURU ====================\n",
      "üó£Ô∏è \"When I think about the world of women's health care, my heart truly goes out to the thousands struggling to receive the necessary services due to clinic closures and extended wait times, especially in rural locales. Your hook, highlighting such a crucial issue, resonated deeply with me. It's an undeniable truth that the market size for enhanced women's health services is vast and urgently needs addressing.\n",
      "\n",
      "However, let's talk about your delivery. I sensed your confidence, but the frequent silences and the monotone delivery could potentially weaken the impact of your message. As someone who believes in passion driving a brand, I want to encourage bringing more energy and enthusiasm into your pitch. The subject matter deserves it!\n",
      "\n",
      "On the business side, I admire the way you've articulated the problem with such clarity and your solution seems promising. Yet, the lack of financial details and no investment ask leave me in a bit of a conundrum. For me to come on board, I need a clearer picture of the business's valuation and potential profitability. Without that, I can't quite see the full picture.\n",
      "\n",
      "Your overall viability score suggests potential, but without the necessary financial structure and an ask, I can't get there. This isn't a reflection on the importance of the issue you're addressing; rather, it's about needing more concrete business details to make a sound investment decision.\n",
      "\n",
      "Thank you for bringing such an important issue to the forefront. I believe with further refinement and details, you could make a significant impact.\"\n",
      "\n",
      "üëâ VERDICT: Need More Info\n",
      "------------------------------------------------------------\n",
      "   üéôÔ∏è Generating audio for The Brand Guru (Voice: nova)...\n",
      "      ‚úÖ Saved: Feedback/feedback_lori.wav\n"
     ]
    }
   ],
   "source": [
    "# import json\n",
    "# import os\n",
    "# from openai import OpenAI\n",
    "# from dotenv import load_dotenv\n",
    "\n",
    "# # Load environment variables\n",
    "# load_dotenv()\n",
    "# key = os.getenv(\"OPENAI_API_KEY\")\n",
    "# client = OpenAI(api_key=key)\n",
    "\n",
    "# ==============================================================================\n",
    "# CLASS 1: PERSONA SYNTHESIS ENGINE (With Final Verdict)\n",
    "# ==============================================================================\n",
    "class PersonaSynthesisEngine:\n",
    "    def __init__(self, acoustic_full_results, business_full_results):\n",
    "        \"\"\"\n",
    "        acoustic_full_results: Dictionary from VoiceAnalyzer containing:\n",
    "                               {'metrics': {...}, 'emotion': '...', 'delivery_score': 0-100}\n",
    "        business_full_results: Dictionary from ContentAnalyzer containing:\n",
    "                               {'transcript': '...', 'analysis': {'scores', 'viability_score', ...}}\n",
    "        \"\"\"\n",
    "        self.acoustic_data = acoustic_full_results\n",
    "        self.business_data = business_full_results.get('analysis', {})\n",
    "        self.transcript = business_full_results.get('transcript', \"\")\n",
    "        \n",
    "        self.interpreted_acoustics = self._interpret_acoustic_data()\n",
    "\n",
    "    def _interpret_acoustic_data(self):\n",
    "        \"\"\"\n",
    "        Translates raw audio metrics into a narrative profile for the LLM.\n",
    "        \"\"\"\n",
    "        metrics = self.acoustic_data.get('metrics', {})\n",
    "        emotion = self.acoustic_data.get('emotion', \"Unknown\")\n",
    "        score = self.acoustic_data.get('delivery_score', 0)\n",
    "        \n",
    "        summary = f\"The speaker's emotional tone was detected as '{emotion}'.\"\n",
    "        summary += f\" They received a Vocal Delivery Score of {score}/100.\"\n",
    "        \n",
    "        # Add nuance based on raw metrics\n",
    "        pitch_var = metrics.get('pitch_variation', 0)\n",
    "        hesitation = metrics.get('hesitation_index', 0)\n",
    "        \n",
    "        if hesitation > 0.20:\n",
    "            summary += \" There were frequent awkward silences (High Hesitation).\"\n",
    "        if pitch_var < 15:\n",
    "            summary += \" The voice was notably monotone and lacked energy.\"\n",
    "            \n",
    "        return summary\n",
    "\n",
    "    def _get_persona_prompt(self, persona_type):\n",
    "        base_instruction = \"\"\"\n",
    "        You are a judge on 'Shark Tank'. \n",
    "        Synthesize the provided data into a first-person critique. \n",
    "        React emotionally to the specific scores provided.\n",
    "        \n",
    "        CRITICAL INSTRUCTION:\n",
    "        End your response with a separate line exactly like this:\n",
    "        \"FINAL RECOMMENDATION: [Invest / Not Invest / Need More Info]\"\n",
    "        \"\"\"\n",
    "\n",
    "        if persona_type == \"The Royalty\":\n",
    "            return base_instruction + \"\"\"\n",
    "            PERSONA: 'The Royalty' (Kevin O'Leary).\n",
    "            - Focus on 'Viability Score' and 'The Ask'.\n",
    "            - If Viability < 50, call them a \"cockroach\" or tell them to stop the madness.\n",
    "            - If Delivery Score is low, say \"You are boring me to death.\"\n",
    "            - TONE: Condescending, financially ruthless, impatient.\n",
    "            \"\"\"\n",
    "        elif persona_type == \"The Tech Visionary\":\n",
    "            return base_instruction + \"\"\"\n",
    "            PERSONA: 'The Tech Visionary' (Mark Cuban).\n",
    "            - Focus on 'Solution Viability' and 'Problem Clarity'.\n",
    "            - If 'Emotional Tone' is 'Nervous', tell them to breathe and pitch again.\n",
    "            - If 'Red Flags' exist, aggressively question their competence.\n",
    "            - TONE: High-energy, direct, allergic to fluff.\n",
    "            \"\"\"\n",
    "        elif persona_type == \"The Brand Guru\":\n",
    "            return base_instruction + \"\"\"\n",
    "            PERSONA: 'The Brand Guru' (Lori Greiner).\n",
    "            - Focus on the 'Hook' and 'Market Size'.\n",
    "            - If 'Delivery Score' > 80, compliment their passion.\n",
    "            - If 'Viability' is low, say \"I can't get there\" gently but firmly.\n",
    "            - TONE: Empathetic, warm, but intuitively sharp.\n",
    "            \"\"\"\n",
    "        else:\n",
    "            return base_instruction\n",
    "\n",
    "    def generate_feedback(self, persona_type=\"The Royalty\"):\n",
    "        print(f\"--- üß† Synthesizing Feedback: {persona_type} ---\")\n",
    "        \n",
    "        system_prompt = self._get_persona_prompt(persona_type)\n",
    "        \n",
    "        # Prepare context\n",
    "        scores = self.business_data.get('scores', {})\n",
    "        viability = self.business_data.get('viability_score', 0)\n",
    "        structure = self.business_data.get('pitch_structure', {})\n",
    "        red_flags = self.business_data.get('red_flags', [])\n",
    "\n",
    "        user_context = f\"\"\"\n",
    "        Here is the entrepreneur's performance data:\n",
    "\n",
    "        === üé§ VOCAL PERFORMANCE ===\n",
    "        {self.interpreted_acoustics}\n",
    "        \n",
    "        === üíº BUSINESS METRICS ===\n",
    "        - Overall Viability Score: {viability}/100\n",
    "        - Problem Clarity: {scores.get('problem')}/10\n",
    "        - Solution Viability: {scores.get('solution')}/10\n",
    "        - The Ask (Valuation): {scores.get('ask')}/10\n",
    "        \n",
    "        === üö© RED FLAGS ===\n",
    "        {\", \".join(red_flags) if red_flags else \"None detected.\"}\n",
    "\n",
    "        === üìù PITCH STRUCTURE ===\n",
    "        - Hook: \"{structure.get('hook_segment', 'Not found')}\"\n",
    "        - Ask: \"{structure.get('ask_segment', 'Not found')}\"\n",
    "\n",
    "        === TRANSCRIPT SNIPPET ===\n",
    "        \"...{self.transcript[:400]}...\"\n",
    "\n",
    "        VERDICT: Are you in or out? Explain why using your unique voice.\n",
    "        Don't forget the FINAL RECOMMENDATION line at the very end.\n",
    "        \"\"\"\n",
    "\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_context}\n",
    "            ],\n",
    "            temperature=0.8\n",
    "        )\n",
    "\n",
    "        return response.choices[0].message.content\n",
    "\n",
    "# ==============================================================================\n",
    "# CLASS 2: SHARK VOICE GENERATOR\n",
    "# ==============================================================================\n",
    "class SharkVoiceGenerator:\n",
    "    def __init__(self, client):\n",
    "        self.client = client\n",
    "\n",
    "    def generate_audio(self, text, persona_type, output_filename):\n",
    "        # Map Personas to OpenAI Voices\n",
    "        voice_map = {\n",
    "            \"The Royalty\": \"onyx\",       # Deep, authoritative (Kevin)\n",
    "            \"The Tech Visionary\": \"echo\", # Resonant, conversational (Mark)\n",
    "            \"The Brand Guru\": \"nova\"     # Energetic, female tone (Lori)\n",
    "        }\n",
    "        \n",
    "        selected_voice = voice_map.get(persona_type, \"alloy\")\n",
    "        \n",
    "        # We strip the \"FINAL RECOMMENDATION\" line from the audio \n",
    "        # because the Shark usually says \"I'm out\" in the text anyway, \n",
    "        # and reading the label \"Final Recommendation\" sounds robotic.\n",
    "        clean_text_for_audio = text.split(\"FINAL RECOMMENDATION:\")[0]\n",
    "\n",
    "        print(f\"   üéôÔ∏è Generating audio for {persona_type} (Voice: {selected_voice})...\")\n",
    "\n",
    "        try:\n",
    "            response = self.client.audio.speech.create(\n",
    "                model=\"tts-1\",\n",
    "                voice=selected_voice,\n",
    "                input=clean_text_for_audio,\n",
    "                response_format=\"wav\"\n",
    "            )\n",
    "            \n",
    "            response.stream_to_file(output_filename)\n",
    "            print(f\"      ‚úÖ Saved: {output_filename}\")\n",
    "            return output_filename\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"      ‚ùå Error generating audio: {e}\")\n",
    "            return None\n",
    "\n",
    "# ==============================================================================\n",
    "# FINAL INTEGRATION & EXECUTION\n",
    "# ==============================================================================\n",
    "\n",
    "# NOTE: Ensure 'data' and 'business_insights' are populated before running this.\n",
    "\n",
    "if 'data' in locals() and 'business_insights' in locals():\n",
    "    # 1. Initialize Engines\n",
    "    engine = PersonaSynthesisEngine(data, business_insights)\n",
    "    voice_gen = SharkVoiceGenerator(client)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"ü¶à FINAL SHARK TANK VERDICT ü¶à\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    # Function to print nicely formatted output\n",
    "    def run_shark_critique(persona, filename):\n",
    "        full_response = engine.generate_feedback(persona_type=persona)\n",
    "        \n",
    "        # Split logic to separate the monologue from the final label\n",
    "        if \"FINAL RECOMMENDATION:\" in full_response:\n",
    "            parts = full_response.split(\"FINAL RECOMMENDATION:\")\n",
    "            monologue = parts[0].strip()\n",
    "            verdict = parts[1].strip()\n",
    "        else:\n",
    "            monologue = full_response\n",
    "            verdict = \"Unknown\"\n",
    "\n",
    "        # Print Visuals\n",
    "        print(f\"\\n{'='*20} {persona.upper()} {'='*20}\")\n",
    "        print(f\"üó£Ô∏è \\\"{monologue}\\\"\")\n",
    "        print(f\"\\nüëâ VERDICT: {verdict}\")\n",
    "        print(\"-\" * 60)\n",
    "        \n",
    "        # Generate Audio\n",
    "        voice_gen.generate_audio(full_response, persona, filename)\n",
    "\n",
    "    # --- RUN ALL SHARKS ---\n",
    "    run_shark_critique(\"The Royalty\", \"Feedback/feedback_kevin.wav\")\n",
    "    run_shark_critique(\"The Tech Visionary\", \"Feedback/feedback_mark.wav\")\n",
    "    run_shark_critique(\"The Brand Guru\", \"Feedback/feedback_lori.wav\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Please run VoiceAnalyzer and ContentAnalyzer first to populate 'data' and 'business_insights'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
